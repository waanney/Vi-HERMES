import os
import time
import asyncio
import pandas as pd
import numpy as np
import google.generativeai as genai
from openai import OpenAI
from dotenv import load_dotenv
from lightrag import LightRAG, QueryParam
from dataclasses import dataclass

# --- 1. SETUP & METRICS ---
load_dotenv()
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

@dataclass
class Metrics:
    input_tokens: int = 0
    output_tokens: int = 0
    total_time: float = 0.0
    generation_time: float = 0.0

tracker = Metrics()

# --- 2. WRAPPER FUNCTIONS ---
async def gemini_complete(prompt, system_prompt=None, history_messages=[], **kwargs) -> str:
    start = time.perf_counter()
    model = genai.GenerativeModel('gemini-1.5-flash')
    full_prompt = (f"System: {system_prompt}\n" if system_prompt else "") + f"User: {prompt}"
    try:
        response = await model.generate_content_async(full_prompt)
        dur = time.perf_counter() - start
        if response.usage_metadata:
            tracker.input_tokens += response.usage_metadata.prompt_token_count
            tracker.output_tokens += response.usage_metadata.candidates_token_count
            tracker.generation_time += dur
        return response.text
    except: return ""

async def openai_embedding(texts: list[str]) -> np.ndarray:
    resp = openai_client.embeddings.create(input=texts, model="text-embedding-3-small")
    return np.array([d.embedding for d in resp.data])

# --- 3. MAIN LOGIC (INDEX + EVAL) ---
async def main():
    DATA_FILE = "viquad_completed.xlsx - Sheet1.csv"
    INDEX_DIR = "./lightrag_index_viquad"
    
    print(f"--- ğŸš€ LIGHTRAG SETUP ---")
    rag = LightRAG(
        working_dir=INDEX_DIR,
        llm_model_func=gemini_complete,
        embedding_func=LightRAG.Embedding(func=openai_embedding, batch_size=12)
    )

    # --- GIAI ÄOáº N 1: INDEXING (BUILD) ---
    # Kiá»ƒm tra náº¿u thÆ° má»¥c chá»©a dá»¯ liá»‡u chÆ°a cÃ³ file JSON thÃ¬ má»›i Index
    if not os.path.exists(os.path.join(INDEX_DIR, "kv_store")):
        print(f"â³ ChÆ°a cÃ³ Index. Äang Ä‘á»c file {DATA_FILE} Ä‘á»ƒ Build...")
        df = pd.read_csv(DATA_FILE)
        contexts = df['context'].astype(str).unique().tolist()
        
        # Insert dá»¯ liá»‡u (Tá»‘n phÃ­ API & Thá»i gian)
        for i, ctx in enumerate(contexts):
            print(f"   + Indexing doc {i+1}/{len(contexts)}...")
            await rag.ainsert(ctx)
        print("âœ… Indexing hoÃ n táº¥t!")
    else:
        print("âœ… ÄÃ£ tÃ¬m tháº¥y Index cÅ©. Bá» qua bÆ°á»›c Build.")

    # --- GIAI ÄOáº N 2: EVALUATION (TEST) ---
    print(f"\n--- ğŸ§ª EVALUATION (HOP 4) ---")
    df = pd.read_csv(DATA_FILE)
    # Láº¥y cÃ¢u há»i khÃ³ (Hop = 4)
    test_row = df[df['hop'] == 4].iloc[0]
    query = test_row['question']
    
    print(f"â“ CÃ¢u há»i: {query}")
    
    start_total = time.perf_counter()
    # Query model
    result = await rag.aquery(query, param=QueryParam(mode="hybrid"))
    end_total = time.perf_counter()
    
    tracker.total_time = end_total - start_total
    
    # --- REPORT ---
    print(f"\n{'='*30}")
    print(f"ğŸ’¡ ÄÃ¡p Ã¡n Model: {result}")
    print(f"ğŸ“ ÄÃ¡p Ã¡n Gá»‘c:  {test_row['answers']}")
    print(f"{'='*30}")
    print(f"ğŸ“Š METRICS:")
    print(f"   - Tá»•ng thá»i gian: {tracker.total_time:.4f}s")
    print(f"   - Thá»i gian LLM suy nghÄ©: {tracker.generation_time:.4f}s")
    print(f"   - Thá»i gian Retrieval: {max(0, tracker.total_time - tracker.generation_time):.4f}s")
    print(f"   - Token Input: {tracker.input_tokens} | Output: {tracker.output_tokens}")

if __name__ == "__main__":
    asyncio.run(main())