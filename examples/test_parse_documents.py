from __future__ import annotations

import asyncio
import json
import os
from pathlib import Path

from dotenv import load_dotenv

from vihermes.Agents.engine import GraphRAGEngine, LLMClient
from vihermes.config.settings import get_settings
from vihermes.lawgraph.neo4j_client import Neo4jClient
from vihermes.lawrag.hybrid import HybridRetriever
from vihermes.lawrag.milvus_client import MilvusClient, MilvusSchemaManager
from vihermes.preprocess.agent_chunker import AgentChunker
from vihermes.preprocess.models import DocumentMetadata
from vihermes.preprocess.parser import DocumentParser
from vihermes.preprocess.pipeline import PreprocessPipeline

load_dotenv()


async def test_parse_store_and_query():
    """Test parsing, storing v√†o database v√† query."""
    print("=" * 70)
    print("Testing: Parse ‚Üí Store ‚Üí Query")
    print("=" * 70)
    print()

    settings = get_settings()

    # Setup databases
    print("üîß Setting up databases...")
    
    # Neo4j
    neo4j = Neo4jClient(
        uri=settings.neo4j_uri,
        user=settings.neo4j_user,
        password=settings.neo4j_password,
    )
    neo4j.init_schema()
    print("‚úÖ Neo4j initialized")

    # Milvus
    milvus_manager = MilvusSchemaManager(
        collection_name=settings.milvus_collection,
        dense_dim=1024,  # multilingual-e5-large dimension
        milvus_uri=f"http://{settings.milvus_host}:{settings.milvus_port}",
    )
    if not milvus_manager.connect():
        print("‚ùå Cannot connect to Milvus. Aborting.")
        return
    milvus_manager.recreate_collection()
    print("‚úÖ Milvus initialized")

    # Setup embedder
    try:
        from sentence_transformers import SentenceTransformer

        model = SentenceTransformer("intfloat/multilingual-e5-large")
        dense_dim = model.get_sentence_embedding_dimension()

        def embedder(text: str):
            vec = model.encode([text], normalize_embeddings=True)[0]
            return vec.tolist()

        print(f"‚úÖ Embedder configured (dim={dense_dim})")
    except Exception as e:
        print(f"‚ùå Could not setup embedder: {e}")
        return

    # Setup pipeline
    pipeline = PreprocessPipeline(
        milvus_manager=milvus_manager,
        neo4j_client=neo4j,
        embedder=embedder,
    )

    # Parse v√† store 2 files
    parser = DocumentParser()
    chunker = AgentChunker(model="gpt-4o")

    files = [
        ("../data/sample_law_1.txt", "law_38_2019", "Law", "Qu·ªëc h·ªôi", "2020-01-01"),
        ("../data/sample_law_2.txt", "decree_126_2020", "Decree", "Ch√≠nh ph·ªß", "2020-07-01"),
    ]

    all_chunks = []
    for file_path, doc_id, doc_type, authority, effect_date in files:
        print(f"\n{'='*70}")
        print(f"üìÑ Processing: {file_path} - {doc_id}")
        print(f"{'='*70}")

        try:
            # 1. Parse
            print(f"\n1Ô∏è‚É£  Parsing file...")
            text = parser.parse(file_path)
            print(f"   ‚úÖ Parsed {len(text)} characters")

            # 2. Chunking v·ªõi Agent
            print(f"\n2Ô∏è‚É£  Chunking v·ªõi AgentChunker...")
            chunks = await chunker.chunk(text)
            print(f"   ‚úÖ Chunked th√†nh {len(chunks)} chunks")

            # Update document_id trong chunks
            for chunk in chunks:
                chunk.document_id = doc_id
            all_chunks.extend(chunks)

            # 3. Create metadata
            metadata = DocumentMetadata(
                document_id=doc_id,
                issuing_authority=authority,
                effect_date=effect_date,
                field="Thu·∫ø",
                status="effective",
            )

            # 4. Store v√†o databases
            print(f"\n3Ô∏è‚É£  Storing v√†o Milvus & Neo4j...")
            
            # Store chunks v√†o Milvus v·ªõi embeddings
            milvus_data = []
            for chunk in chunks:
                embedding = embedder(chunk.text)
                milvus_data.append({
                    "id": chunk.id,
                    "original_doc_id": chunk.document_id,
                    "text": chunk.text,
                    "source": doc_type,
                    "url": "",  # Empty string instead of None for varchar field
                    "dense_vec": embedding,
                    "sparse_vec": {},
                })
            if milvus_data:
                milvus_manager.insert(milvus_data)
                milvus_manager.flush()
                print(f"   ‚úÖ Stored {len(milvus_data)} chunks v√†o Milvus")

            # Store document node v√†o Neo4j
            props = {
                "issuing_authority": metadata.issuing_authority,
                "effect_date": metadata.effect_date,
                "field": metadata.field,
                "status": metadata.status,
            }
            neo4j.upsert_node(
                label=doc_type,
                node_id=doc_id,
                properties=props,
            )
            print(f"   ‚úÖ Stored document node v√†o Neo4j")

            # Extract v√† store relations
            from vihermes.Agents.relations import extract_all
            relations = extract_all(source_id=doc_id, text=text)
            for rel in relations:
                neo4j.upsert_edge(
                    src_label=doc_type,
                    src_id=rel.source_id,
                    relation=rel.relation,
                    tgt_label="Law",  # Default target type
                    tgt_id=rel.target_id,
                )
            print(f"   ‚úÖ Stored {len(relations)} relations v√†o Neo4j")

            # 5. Create relation t·ª´ Decree ƒë·∫øn Law
            if doc_type == "Decree":
                neo4j.upsert_edge(
                    src_label="Decree",
                    src_id="decree_126_2020",
                    relation="GUIDES",
                    tgt_label="Law",
                    tgt_id="law_38_2019",
                )
                print(f"   ‚úÖ Created GUIDES relation: Decree ‚Üí Law")

        except Exception as e:
            print(f"   ‚ùå Error: {e}")
            import traceback
            traceback.print_exc()

    # Flush to make data searchable
    print(f"\n{'='*70}")
    print("üíæ Flushing data to make searchable...")
    milvus_manager.flush()
    # Ensure collection is loaded into memory
    if milvus_manager.client:
        try:
            milvus_manager.client.load_collection(collection_name=settings.milvus_collection)
            print("‚úÖ Collection loaded into memory")
            # Check collection stats
            try:
                stats = milvus_manager.client.get_collection_stats(collection_name=settings.milvus_collection)
                print(f"üìä Collection stats: {stats}")
            except Exception as e:
                print(f"‚ö†Ô∏è  Could not get collection stats: {e}")
        except Exception as e:
            print(f"‚ö†Ô∏è  Collection load warning: {e}")
    print("‚úÖ Data flushed and ready for search")

    # Test query
    print(f"\n{'='*70}")
    print("üîç Testing Query")
    print(f"{'='*70}")

    # Setup query components
    milvus_client = MilvusClient(
        host=settings.milvus_host,
        port=settings.milvus_port,
        collection=settings.milvus_collection,
        dense_dim=dense_dim,
    )
    milvus_client.set_embedder(embedder, auto_detect_dim=True)

    retriever = HybridRetriever(vector=milvus_client, graph=neo4j)
    llm = LLMClient(model=settings.llm_model)
    engine = GraphRAGEngine(llm=llm)

    # Test queries - d·ª±a tr√™n n·ªôi dung Lu·∫≠t Qu·∫£n l√Ω thu·∫ø 38/2019/QH14
    queries = [
        # C√¢u h·ªèi v·ªÅ ƒë·ªãnh nghƒ©a (ƒêi·ªÅu 3)

        "C∆° quan qu·∫£n l√Ω thu·∫ø l√† g√¨?",
        "Qu·∫£n l√Ω thu·∫ø ƒë∆∞·ª£c hi·ªÉu nh∆∞ th·∫ø n√†o?",
        
        # C√¢u h·ªèi v·ªÅ ƒë·ªëi t∆∞·ª£ng √°p d·ª•ng (ƒêi·ªÅu 2)
        "Lu·∫≠t Qu·∫£n l√Ω thu·∫ø 38/2019 √°p d·ª•ng ƒë·ªëi v·ªõi nh·ªØng ƒë·ªëi t∆∞·ª£ng n√†o?",
        
        # C√¢u h·ªèi v·ªÅ ng∆∞·ªùi n·ªôp thu·∫ø (ƒêi·ªÅu 5)
        "Ng∆∞·ªùi n·ªôp thu·∫ø bao g·ªìm nh·ªØng ai?",
        
        # C√¢u h·ªèi v·ªÅ quy·ªÅn (ƒêi·ªÅu 6)
        "Ng∆∞·ªùi n·ªôp thu·∫ø c√≥ nh·ªØng quy·ªÅn g√¨?",
        
        # C√¢u h·ªèi v·ªÅ nguy√™n t·∫Øc (ƒêi·ªÅu 4)
        "Nguy√™n t·∫Øc qu·∫£n l√Ω thu·∫ø l√† g√¨?",
        
        # C√¢u h·ªèi v·ªÅ ph·∫°m vi (ƒêi·ªÅu 1)
        "Lu·∫≠t Qu·∫£n l√Ω thu·∫ø 38/2019 quy ƒë·ªãnh v·ªÅ nh·ªØng v·∫•n ƒë·ªÅ g√¨?",
        
        # C√¢u h·ªèi v·ªÅ Ngh·ªã ƒë·ªãnh 126/2020/Nƒê-CP
        "K√™ khai thu·∫ø l√† g√¨ theo Ngh·ªã ƒë·ªãnh 126/2020?",
        "N·ªôp thu·∫ø ƒë∆∞·ª£c hi·ªÉu nh∆∞ th·∫ø n√†o?",
        "·∫§n ƒë·ªãnh thu·∫ø l√† g√¨?",
        "Ng∆∞·ªùi n·ªôp thu·∫ø ph·∫£i ƒëƒÉng k√Ω thu·∫ø trong th·ªùi h·∫°n bao l√¢u?",
        "H·ªì s∆° ƒëƒÉng k√Ω thu·∫ø bao g·ªìm nh·ªØng g√¨?",
        "Ng∆∞·ªùi n·ªôp thu·∫ø c√≥ th·ªÉ k√™ khai thu·∫ø b·∫±ng nh·ªØng c√°ch n√†o?",
        "Th·ªùi h·∫°n n·ªôp thu·∫ø ƒë∆∞·ª£c quy ƒë·ªãnh nh∆∞ th·∫ø n√†o?",
        "Ng∆∞·ªùi n·ªôp thu·∫ø c√≥ th·ªÉ n·ªôp thu·∫ø b·∫±ng nh·ªØng ph∆∞∆°ng th·ª©c n√†o?",
    ]

    for query in queries:
        print(f"\n{'‚îÄ'*70}")
        print(f"‚ùì Query: {query}")
        print(f"{'‚îÄ'*70}")

        try:
            # Retrieve
            hits = retriever.retrieve(query, k=3)
            print(f"üìä Retrieved {len(hits)} results")

            if hits:
                for i, hit in enumerate(hits, 1):
                    print(f"   {i}. {hit.chunk.id} (score: {hit.score:.4f})")
                    print(f"      Text: {hit.chunk.text[:100]}...")

                # Generate answer
                print(f"\nüí¨ Generating answer...")
                answer = engine.generate(query=query, retrieved=hits)
                print(f"‚úÖ Answer:\n{answer.answer}")
                print(f"\nüìö Sources:")
                for src in answer.sources:
                    print(f"   - {src}")
                if answer.graph_trace:
                    print(f"\nüîó Graph trace:")
                    for trace in answer.graph_trace:
                        print(f"   - {trace}")
            else:
                print("‚ö†Ô∏è  No results found")

        except Exception as e:
            print(f"‚ùå Error: {e}")
            import traceback
            traceback.print_exc()

    print(f"\n{'='*70}")
    print("‚úÖ Test completed!")
    print(f"{'='*70}")


if __name__ == "__main__":
    asyncio.run(test_parse_store_and_query())

